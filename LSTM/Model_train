# -*- coding: utf-8 -*-
"""
Created on Wed Mar 28 08:49:45 2018

@author: Akhtar Munir
"""

import numpy as np
np.random.seed(1337)  # for reproducibility

from keras.preprocessing import sequence
from keras.models import Sequential
from keras.layers import Dense, Dropout, Embedding, LSTM, Input, Bidirectional
from keras.callbacks import EarlyStopping, ModelCheckpoint

import json

classes = 5
maxlen = 80000  # cut texts after this number of words (among top max_features most common words)
batch_size = 128
epochs = 2

print('Loading data...')
#X_train = np.load("F:/Programming/Python programming/data sets/DLD/x_train.npy")
#y_train = np.load("F:/Programming/Python programming/data sets/DLD/y_train.npy")
#X_test = np.load("F:/Programming/Python programming/data sets/DLD/x_test.npy")
#Y_test = np.load("F:/Programming/Python programming/data sets/DLD/y_test.npy")

Expected_class = np.load("E:/auther det/indices_y_train.npy")
X_train = np.load("E:/auther det/x_train.npy")
y_train = np.load("E:/auther det/y_train.npy")
X_test = np.load("E:/auther det/x_test.npy")
Y_test = np.load("E:/auther det/y_test.npy")
#print("x_train: ",X_train)
print(len(X_train), 'train sequences')

print("Pad sequences (samples x time)")
X_train = sequence.pad_sequences(X_train, maxlen=maxlen)
X_test = sequence.pad_sequences(X_test, maxlen=maxlen)
maxfeatures = len(X_train)*maxlen
print(maxfeatures)
#print(X_train)
print('X_test shape:', X_test.shape)
print('X_train shape:', X_train.shape)
print("training started!!")

#####################################################Nural Network Model#############################################

model = Sequential()
model.add(Embedding(388548, 3, input_length=maxlen))
#model.add(LSTM(32,activation='tanh', recurrent_activation='hard_sigmoid',
#               dropout=0.2, recurrent_dropout=0.2))
model.add(Bidirectional(LSTM(64)))
model.add(Dropout(0.5))
model.add(Dense(5, activation='sigmoid'))
#####################################################Nural Network Model#############################################
# try using different optimizers and different optimizer configs
model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])
print(model.summary())
# Model saving callback
checkpointer = ModelCheckpoint(filepath="model.json", monitor='val_acc', verbose=1, save_best_only=True)
# train
model.fit(X_train, y_train,
          validation_data=[X_test, Y_test],
          epochs=epochs, verbose=1)

scores = model.evaluate(X_train, y_train)
print("\ntrain-%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))
scores = model.evaluate(X_test, Y_test)
print("\nval-%s: %.2f%%" % (model.metrics_names[1], scores[1]*100))

pred = model.predict(X_train)
predict_classes=np.argmax(pred,axis=1)
#print("predict output: ",pred)
print("Predicted classes: {} ",predict_classes)
print("Expected classes: {} ",Expected_class)

def runit(model, inp):
    inp = np.array(inp,dtype=np.float32)
    pred = model.predict(inp)
    return np.argmax(pred[0])

val = runit(model,[X_test[4]])
print("predicted value: ",val)
if val == 1:
    print("is expert developer!!!")
else:
    print("is novice developer!!!")

#Saving model    
#model_json = model.to_json()
#with open("model.json", "w") as json_file:
#    json_file.write(model_json)
## serialize weights to HDF5
#model.save_weights("model.h5")
#print("Saved model to disk")
